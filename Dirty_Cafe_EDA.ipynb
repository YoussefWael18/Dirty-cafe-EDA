{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889499db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script is for cleaning and analyzing a dataset related to a cafe's transactions.\n",
    "It includes handling missing values, replacing erroneous entries, and creating new columns based on existing data.\n",
    "The dataset is expected to have columns like 'Payment_Method', 'Location', 'Transaction_Date',\n",
    "'Item', 'Quantity', and 'Transaction_Status'.\n",
    "The script also includes comments indicating the handling of missing data and the rationale behind each step.\n",
    "The final output will be a cleaned DataFrame ready for further analysis or modeling.\n",
    "you can find the dataset at https://www.kaggle.com/datasets/ahmedmohamed2003/cafe-sales-dirty-data-for-cleaning-training\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cbc463",
   "metadata": {},
   "source": [
    "### __Importing the libaries__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3172333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8c5583",
   "metadata": {},
   "source": [
    "### __Reading the data__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d1baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r\"d:\\Project  EDA\\dirty_cafe_sales.csv\"\n",
    "df=pd.read_csv(path)\n",
    "pd.set_option('display.max_columns', None) # to display all columns in the dataframe\n",
    "pd.set_option('display.max_rows', None) # to display all rows in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd8a043",
   "metadata": {},
   "source": [
    "### __Checking the data__ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da8e66c",
   "metadata": {},
   "source": [
    "#####  The data has null values and the data types needs to be converted to its correct data types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa717fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5467be5",
   "metadata": {},
   "source": [
    "##### There is 3 types of missing data  (Unknown,Error,direct null value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ba8d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397ef1c9",
   "metadata": {},
   "source": [
    "### __Cleaning the Data__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ec734c",
   "metadata": {},
   "source": [
    "##### Dropping the Transaction ID column as it is not a feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2a2bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Transaction ID'], inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef18a737",
   "metadata": {},
   "source": [
    "##### Renaming the columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722cbd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Transaction Date': 'Transaction_Date'},inplace=True)\n",
    "df.rename(columns={'Payment Method': 'Payment_Method'},inplace=True)\n",
    "df.rename(columns={'Total Spent': 'Total_Spent'},inplace=True)\n",
    "df.rename(columns={'Price Per Unit': 'Unit_Price'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297924ef",
   "metadata": {},
   "source": [
    "##### Replacing ERRORS and UNKNOWN with 0 to be able to convert them into float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0de457",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Quantity'] == 'ERROR', 'Quantity'] = 0\n",
    "df.loc[df['Quantity'] == 'UNKNOWN', 'Quantity'] = 0\n",
    "df.loc[df['Total_Spent'] == 'ERROR', 'Total_Spent'] = 0\n",
    "df.loc[df['Total_Spent'] == 'UNKNOWN', 'Total_Spent'] = 0\n",
    "df.loc[df['Unit_Price'] == 'ERROR', 'Unit_Price'] = 0\n",
    "df.loc[df['Unit_Price'] == 'UNKNOWN', 'Unit_Price'] = 0\n",
    "df.fillna(0, inplace=True) # replace NaN values with 0 to deal with them easily later\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24b71a0",
   "metadata": {},
   "source": [
    "##### Converting each data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc71909",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Transaction_Date'] = pd.to_datetime(df['Transaction_Date'], errors='coerce')\n",
    "df['Quantity'] = df['Quantity'].astype(int)\n",
    "df['Total_Spent'] = df['Total_Spent'].astype(float)\n",
    "df['Unit_Price'] = df['Unit_Price'].astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64391722",
   "metadata": {},
   "source": [
    "##### Creating Transaction status column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cda4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Transaction_Status'] = np.where(df['Quantity'] == 0, 'Cancelled', 'Successful') # if quantity is zero, then transaction is 'Cancelled', otherwise successful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63880ba",
   "metadata": {},
   "source": [
    "### __Dealing with missing data__ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec970be",
   "metadata": {},
   "source": [
    "\n",
    "| MCAR  | Reason |How it will be handled|             \n",
    "|---------|------|-------------------------------------------------------------------------|            \n",
    "| Items  |The missing values (UNKNOWN or ERROR or 0) in the Item column seem to be random occurrences|Will be filled using a map of item to price unit \n",
    "| Unit price  |The missing values (UNKNOWN or ERROR or 0) in the Item column seem to be random occurrences|Will be filled using a map of price to item unit                       \n",
    "| Location | The Location column has missing data (UNKNOWN or ERROR or 0) that seems to be random|Will use proportional imputation using  local mode\n",
    "| Transaction Date | The Location column has missing data at random|Dropping         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea9a406",
   "metadata": {},
   "source": [
    "##### Creating a map for filling null values of item using unit price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7185cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_to_item_map = df.groupby('Unit_Price')['Item'].apply( # it will create a mapping of Unit_Price to Item but there still will have some null values if there are no items for a specific price\n",
    "    lambda x: x.mode()[0] if not x.mode().empty else None\n",
    ").to_dict() \n",
    "price_to_item_map.pop(0)  # Remove the entry for price 0 as it was wrong\n",
    "price_to_item_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a2e726",
   "metadata": {},
   "source": [
    "##### Filling Item column using price to item map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed004b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Item'] == 'UNKNOWN', 'Item'] = df.loc[df['Item'] == 'UNKNOWN', 'Unit_Price'].map(price_to_item_map)\n",
    "df.loc[df['Item'] == 'ERROR', 'Item'] = df.loc[df['Item'] == 'ERROR', 'Unit_Price'].map(price_to_item_map)\n",
    "df.loc[df['Item'] == 0, 'Item'] = df.loc[df['Item'] == 0, 'Unit_Price'].map(price_to_item_map)\n",
    "df['Item'] = df['Item'].fillna(df['Unit_Price'].map(price_to_item_map)) \n",
    "df.dropna(subset=['Item'], inplace=True)  # Drop rows that couldnt be mapped from price to item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb924196",
   "metadata": {},
   "source": [
    "##### Creating a map for filling null values of unit price  using item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023735ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_to_price_map = df.groupby('Item')['Unit_Price'].apply(\n",
    "    lambda x: x.mode()[0] if not x.mode().empty else None\n",
    ").to_dict()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c72fdd",
   "metadata": {},
   "source": [
    "##### Filling null values using the map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9bf648",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Unit_Price'] == 0, 'Unit_Price'] = np.nan # replace quantity equal zero with NaN to drop them later\n",
    "df.fillna({'Unit_Price': df['Item'].map(item_to_price_map)}, inplace=True) # fill NaN values in Unit_Price with the corresponding price from item_to_price_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d50f962",
   "metadata": {},
   "source": [
    "##### Replacing ERRORS and UNKNOWNS in location column with zero to deal with them faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773e5ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Location'] == 'ERROR', 'Location'] = 0 # replace 'ERROR' with 0 for Location\n",
    "df.loc[df['Location'] == 'UNKNOWN', 'Location'] = 0 # replace 'UNKNOWN' with 0 for Location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196448d6",
   "metadata": {},
   "source": [
    "##### Filling the location null values Using proportional imputation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a2c464",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Location'].value_counts() # there is 3936 rows with location as zero, which is not valid transaction, so we will use proportional imputation to fill these values becuase we have enough data lose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18562c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_locations = ['In-store', 'Takeaway'] # putting the locations we want to impute\n",
    "imputation_proportions = [0.5, 0.5]  # Assuming equal distribution for simplicity, adjust as needed\n",
    "num_missing = (df['Location'] == 0).sum() # Count the number of missing values in 'Location' column\n",
    "imputed_values = np.random.choice(   # generate random values from the specified locations based on the defined proportions\n",
    "    imputation_locations,\n",
    "    size=num_missing,\n",
    "    p=imputation_proportions\n",
    ")\n",
    "missing_indices = df[df['Location'] == 0].index # Get the indices of the rows where Location is 0\n",
    "df.loc[missing_indices, 'Location'] = imputed_values  # Fill the missing values with the imputed values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc57fcda",
   "metadata": {},
   "source": [
    "##### Dropping the null values of Transaction date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b0e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['Transaction_Date'], inplace=True)  # Drop rows with missing Transaction_Date values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab9e523",
   "metadata": {},
   "source": [
    "\n",
    "| MAR  | Reason |How it will be handled|             \n",
    "|---------|------|-------------------------------------------------------------------------|            \n",
    "| Items  |The missing values can be related to  quantity and unit price |Will be filled using a Quantity * Unit price            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396a310c",
   "metadata": {},
   "source": [
    "##### Filling the total spent column with Quantity * Unit price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ab24bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Total_Spent'] = df['Quantity'] * df['Unit_Price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13e8e6e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| MNAR | Reason |How it will be handled|             \n",
    "|---------|------|-------------------------------------------------------------------------|            \n",
    "| Payment Method|Transaction was done by a customer who didn't want to provide their payment method| using Missingness Indicator            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275443c5",
   "metadata": {},
   "source": [
    "##### Replacing ERRORS and UNKNOWNS in Payment method  column with zero to deal with them faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaca3d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Payment_Method'] == 'ERROR', 'Payment_Method'] = 0 # replace 'ERROR' with 0 for Payment_Method\n",
    "df.loc[df['Payment_Method'] == 'UNKNOWN', 'Payment_Method'] = 0 # replace 'UNKNOWN' with 0 for Payment_Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba31b8b",
   "metadata": {},
   "source": [
    "##### Replacing the zeros in the payment method column with Missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fae07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Payment_Method'] == 0, 'Payment_Method'] = \"Missing\"  # replace 0 with \"Missing\" for Payment_Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03af60bf",
   "metadata": {},
   "source": [
    "# __Visualizing the Data__ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506837ef",
   "metadata": {},
   "source": [
    "## Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245ae5ca",
   "metadata": {},
   "source": [
    "#### visualizing the Categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c0157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Item',data=df)\n",
    "plt.title('Count of Items') \n",
    "# we can see that the Juice is the most order while smoothie being least ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60b36b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Location',data=df)\n",
    "plt.title('Count of Locations') \n",
    "# both store and takeaway are nearly the same which suggest improvment to the enviroment of store as more customers in store the more they will spend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c39d066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentages\n",
    "status_counts = df['Transaction_Status'].value_counts(normalize=True) * 100  \n",
    "# Create pie chart\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.pie(status_counts, labels=status_counts.index, autopct='%1.1f%%', startangle=90, colors=['#66b3ff','#99ff99','#ff9999'])\n",
    "plt.title('Transaction Status Distribution (%)')\n",
    "plt.axis('equal') # Equal aspect ratio to keep the pie circular\n",
    "plt.show() \n",
    "# only 5% of transaction are cancelled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ade9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Payment_Method',data=df)\n",
    "plt.title('Count of Payment Methods')  \n",
    "# this Shows the customers prefer to hide the payment method but with the available data it shows it is nearly equal "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc406eb",
   "metadata": {},
   "source": [
    "###### we can see that a large amount of people decide not to say their payment method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff81855",
   "metadata": {},
   "source": [
    "#### Visualizing the Numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ca79fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x='Quantity', data=df)\n",
    "plt.title('Distribution of Quantity')  \n",
    "# this is very important as it shows customer tends to buy large quantity of 5 than any other quantity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc09ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x='Total_Spent',bins=15, data=df,kde=True)\n",
    "plt.title('Distribution of Total_Spent') \n",
    "# This shows that the Total spent values is skewed to the right , it indicates that most transactions have a low value , with a smaller number of transactions having a much higher value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda5c87f",
   "metadata": {},
   "source": [
    "## Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004dcc97",
   "metadata": {},
   "source": [
    "#### Visualizing numerical vs categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e986007",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns # to check the columns in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9ea233",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='Item', y='Total_Spent', data=df)\n",
    "plt.title('Total Spent by Item')\n",
    "# there is no outliers in the Total Spent by Item, which is good, it means that the data is clean and there is no erroneous data in the Total Spent column\n",
    "# salad and smoothies have the highest mdeian indicating they are generally associated with higher spending\n",
    "# while coffee and tea have lower median spending indicating they are generally associated with lower spending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecab22d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Location', y='Total_Spent', data=df)\n",
    "plt.title('Total Spent by Payment Method') \n",
    "# this shows that the total spent is slightly higher in store than takeaway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527c1fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='Total_Spent', y='Transaction_Date', data=df)\n",
    "plt.title('Total Spent Over Time') \n",
    "# This shows the trend of total spent over time, whice started increasing the the last few months of 2022\n",
    "# This indicates that the cafe has been performing well in the last few months of 2022 \n",
    "# that maybe as due to coronavirus restrictions being lifted and people returning to cafes and restaurants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc085de",
   "metadata": {},
   "source": [
    "#### Visualizing numerical vs numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6608fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Unit_Price', y='Quantity', data=df)\n",
    "plt.title('Unit Price vs Quantity')\n",
    "# this shows that Quantity is the same for all unit prices \n",
    "# indicationg that the price does not affect the quantity purchased, which is expected as customers generally buy the same quantity regardless of the price of the item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6abf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='Quantity',y='Total_Spent',data=df)\n",
    "plt.title('Total Spent vs Quantity')\n",
    "# This makes alot of sense as the quantity increase the total spent increase "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f94d747",
   "metadata": {},
   "source": [
    "#### visualizing numerical vs categorical data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a0747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Location', hue='Payment_Method', data=df)\n",
    "plt.title('Payment Method by Location') \n",
    "# this shows that customers tend to pay using credit card or digitial wallet in takeway than cash "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859b2c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Payment_Method', hue='Transaction_Status', data=df)\n",
    "plt.title('Payment Method by Transaction_Status') \n",
    "# The vast majority of transactions, regardless of payment method, are successful\n",
    "#The proportion of cancelled transactions appears to be relatively consistent across all payment methods. \n",
    "# There isn't a single payment method that seems to have a disproportionately high rate of cancelled transactions.\n",
    "# That means that the cancelation is from the customer not due to technical problem or bad customer service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce0ffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Payment_Method', hue='Location', data=df)\n",
    "plt.title('Payment Method by Location') \n",
    "# We see Cash and credit card is more in store   \n",
    "# while digital wallet is more in takeaway that maybe becuase customer are in a hurry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8401df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_tab = pd.crosstab(df['Location'], df['Item'])\n",
    "cross_tab.plot(kind='bar', stacked=True, figsize=(10, 6)) \n",
    "# items does not differ wether it is in store or takeaway with tea being the most orderd and cake being least ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896b2866",
   "metadata": {},
   "source": [
    "## Feature Correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2290befd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features=df.select_dtypes('number')\n",
    "plt.figure(figsize=(14, 12))\n",
    "correlation_matrix=num_features.corr()\n",
    "sns.heatmap(correlation_matrix,cmap='RdYlBu',fmt=\".1f\",annot=True)\n",
    "# This shows a great correlation between quantity and total spent which makes alot of sense\n",
    "#This also shows a great correlation between unit price and total spent whice also makes alot of sense \n",
    "# Quantity and unit price is not related at all as their is nothing in common between them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffecd371",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2426ea46",
   "metadata": {},
   "source": [
    "## __Conclusion__\n",
    "####  This EDA provided valuable insights into the Dirty Cafe dataset, including customer behavior, sales trends, and key performance factors. After cleaning the data by handling missing values and inconsistencies, patterns emerged that can guide business decisions—such as identifying popular items, understanding peak sales periods, and evaluating payment method preferences. These findings can help the cafe optimize its operations, enhance customer satisfaction, and ultimately increase profitability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
